{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6883_FinalProject_Modelling_top50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw899-bEPk96",
        "colab_type": "text"
      },
      "source": [
        "# ResNet Training with top-50 artists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70B0YsqWgmnZ",
        "colab_type": "code",
        "outputId": "296271b3-06fe-4920-8dac-8119fd6388f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# model and learning\n",
        "import numpy as np\n",
        "import h5py\n",
        "import cv2 as cv\n",
        "\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import keras as ks\n",
        "\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "\n",
        "import os as os\n",
        "import pathlib as pl\n",
        "from PIL import ImageFile\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlSOcdnZhxh2",
        "colab_type": "code",
        "outputId": "af706c3f-a1f8-464f-b4ae-3aab9e8f943b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "my_data_dir = '/content/drive/My Drive/DataForColab/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiWlUsagkszA",
        "colab_type": "text"
      },
      "source": [
        "## GPU Set Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOguF_hgmVnm",
        "colab_type": "code",
        "outputId": "e9708c67-a83a-4613-abbf-2b25a49a5c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrG6iLwgh1Ha",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TZnpQHphyYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(withGPU=True):\n",
        "    TRAIN_LOCATION = my_data_dir + 'ArtworksReducedTVT/train'\n",
        "    VAL_LOCATION = my_data_dir + 'ArtworksReducedTVT/val'\n",
        "    TRAIN_IMAGES = pl.Path(TRAIN_LOCATION)\n",
        "    VAL_IMAGES = pl.Path(VAL_LOCATION)\n",
        "    CLASSES = [item.name for item in TRAIN_IMAGES.glob('*')]\n",
        "    CLASSES.sort()\n",
        "    BATCH_SIZE = 256\n",
        "    EPOCHS = 20\n",
        "    IMG_WIDTH = 200\n",
        "    IMG_HEIGHT = 200\n",
        "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "    image_generator = ks.preprocessing.image.ImageDataGenerator(rescale=1. / 255,\n",
        "                                                                featurewise_center=True,\n",
        "                                                                featurewise_std_normalization=True)\n",
        "\n",
        "    image_generator.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32).reshape((1, 1, 3))  # ordering: [R, G, B]\n",
        "    image_generator.std = np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape((1, 1, 3))\n",
        "\n",
        "    train_data_gen = image_generator.flow_from_directory(directory=TRAIN_IMAGES,\n",
        "                                                         batch_size=BATCH_SIZE,\n",
        "                                                         shuffle=True,\n",
        "                                                         target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                         color_mode='rgb',\n",
        "                                                         class_mode='categorical',\n",
        "                                                         classes=CLASSES,\n",
        "                                                         interpolation='lanczos')\n",
        "    \n",
        "    val_data_gen = image_generator.flow_from_directory(directory=VAL_IMAGES,\n",
        "                                                       batch_size=BATCH_SIZE,\n",
        "                                                       shuffle=True,\n",
        "                                                       target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                       color_mode='rgb',\n",
        "                                                       class_mode='categorical',\n",
        "                                                       classes=CLASSES,\n",
        "                                                       interpolation='lanczos')\n",
        "    \n",
        "\n",
        "    input_tensor = ks.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "    base_model = InceptionResNetV2(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "    # add a global spatial average pooling layer\n",
        "    x = base_model.output\n",
        "    x = ks.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(x)\n",
        "    x = ks.layers.BatchNormalization()(x)\n",
        "    # TODO: ADD FLATTEN\n",
        "    # let's add a fully-connected layer\n",
        "    x = ks.layers.Dense(256, activation='relu')(x)\n",
        "    x = ks.layers.Dropout(rate=0.2)(x)\n",
        "    x = ks.layers.Dense(256, activation='relu')(x)\n",
        "    # and a logistic layer\n",
        "    predictions = ks.layers.Dense(len(CLASSES), activation='softmax')(x)\n",
        "\n",
        "    csv_logger = CSVLogger(my_data_dir + \"model_history_log.csv\", append=True)\n",
        "\n",
        "    if withGPU:\n",
        "      with tf.device('/device:GPU:0'):\n",
        "        model = ks.Model(inputs=base_model.input, outputs=predictions)\n",
        "        \n",
        "        for layer in base_model.layers:\n",
        "          layer.trainable = False\n",
        "          \n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=ks.optimizers.Adam(lr=1e-04),\n",
        "                      metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        "    else:\n",
        "      model = ks.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "      for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "      model.compile(loss='categorical_crossentropy',\n",
        "                    optimizer=ks.optimizers.Adam(lr=1e-04),\n",
        "                    metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        "\n",
        "    model.fit_generator(train_data_gen, epochs=EPOCHS, validation_data=val_data_gen,\n",
        "                      callbacks=[csv_logger], verbose=1)\n",
        "\n",
        "    model.save(my_data_dir + \"save_model_top50_resnet_longerTraining\")\n",
        "\n",
        "    return model, train_data_gen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uijdfajh0Qc",
        "colab_type": "code",
        "outputId": "e2de015c-4934-492b-b55e-674bf9ef56a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        }
      },
      "source": [
        "model_output, data_gen = main(True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 27806 images belonging to 50 classes.\n",
            "Found 3344 images belonging to 50 classes.\n",
            "Epoch 1/20\n",
            "109/109 [==============================] - 324s 3s/step - loss: 3.7449 - accuracy: 0.0943 - top_k_categorical_accuracy: 0.2678 - val_loss: 3.7349 - val_accuracy: 0.1181 - val_top_k_categorical_accuracy: 0.3047\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 304s 3s/step - loss: 3.1805 - accuracy: 0.2100 - top_k_categorical_accuracy: 0.4686 - val_loss: 3.6225 - val_accuracy: 0.1800 - val_top_k_categorical_accuracy: 0.4208\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 310s 3s/step - loss: 2.8368 - accuracy: 0.2821 - top_k_categorical_accuracy: 0.5702 - val_loss: 4.3075 - val_accuracy: 0.2285 - val_top_k_categorical_accuracy: 0.5024\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 311s 3s/step - loss: 2.5986 - accuracy: 0.3326 - top_k_categorical_accuracy: 0.6290 - val_loss: 3.4631 - val_accuracy: 0.2545 - val_top_k_categorical_accuracy: 0.5475\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 311s 3s/step - loss: 2.4263 - accuracy: 0.3628 - top_k_categorical_accuracy: 0.6719 - val_loss: 2.8418 - val_accuracy: 0.2721 - val_top_k_categorical_accuracy: 0.5783\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 311s 3s/step - loss: 2.2977 - accuracy: 0.3910 - top_k_categorical_accuracy: 0.7017 - val_loss: 2.9688 - val_accuracy: 0.2937 - val_top_k_categorical_accuracy: 0.5903\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 311s 3s/step - loss: 2.1899 - accuracy: 0.4103 - top_k_categorical_accuracy: 0.7256 - val_loss: 2.9598 - val_accuracy: 0.2990 - val_top_k_categorical_accuracy: 0.6011\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 312s 3s/step - loss: 2.1007 - accuracy: 0.4327 - top_k_categorical_accuracy: 0.7452 - val_loss: 4.8962 - val_accuracy: 0.3077 - val_top_k_categorical_accuracy: 0.6083\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 311s 3s/step - loss: 2.0281 - accuracy: 0.4524 - top_k_categorical_accuracy: 0.7603 - val_loss: 4.3482 - val_accuracy: 0.3047 - val_top_k_categorical_accuracy: 0.6127\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 310s 3s/step - loss: 1.9724 - accuracy: 0.4652 - top_k_categorical_accuracy: 0.7724 - val_loss: 2.4628 - val_accuracy: 0.3158 - val_top_k_categorical_accuracy: 0.6217\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 311s 3s/step - loss: 1.9082 - accuracy: 0.4756 - top_k_categorical_accuracy: 0.7843 - val_loss: 3.1828 - val_accuracy: 0.3257 - val_top_k_categorical_accuracy: 0.6355\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 310s 3s/step - loss: 1.8516 - accuracy: 0.4921 - top_k_categorical_accuracy: 0.7957 - val_loss: 4.2225 - val_accuracy: 0.3343 - val_top_k_categorical_accuracy: 0.6474\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 311s 3s/step - loss: 1.8204 - accuracy: 0.4983 - top_k_categorical_accuracy: 0.8013 - val_loss: 4.6655 - val_accuracy: 0.3289 - val_top_k_categorical_accuracy: 0.6426\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 312s 3s/step - loss: 1.7673 - accuracy: 0.5121 - top_k_categorical_accuracy: 0.8130 - val_loss: 3.5147 - val_accuracy: 0.3412 - val_top_k_categorical_accuracy: 0.6465\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 311s 3s/step - loss: 1.7292 - accuracy: 0.5236 - top_k_categorical_accuracy: 0.8200 - val_loss: 3.9269 - val_accuracy: 0.3340 - val_top_k_categorical_accuracy: 0.6453\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 310s 3s/step - loss: 1.6793 - accuracy: 0.5303 - top_k_categorical_accuracy: 0.8308 - val_loss: 2.9588 - val_accuracy: 0.3406 - val_top_k_categorical_accuracy: 0.6540\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 311s 3s/step - loss: 1.6483 - accuracy: 0.5365 - top_k_categorical_accuracy: 0.8344 - val_loss: 2.9649 - val_accuracy: 0.3520 - val_top_k_categorical_accuracy: 0.6654\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 310s 3s/step - loss: 1.6097 - accuracy: 0.5490 - top_k_categorical_accuracy: 0.8427 - val_loss: 3.5023 - val_accuracy: 0.3451 - val_top_k_categorical_accuracy: 0.6588\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 312s 3s/step - loss: 1.5839 - accuracy: 0.5563 - top_k_categorical_accuracy: 0.8472 - val_loss: 4.5880 - val_accuracy: 0.3433 - val_top_k_categorical_accuracy: 0.6564\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 311s 3s/step - loss: 1.5554 - accuracy: 0.5622 - top_k_categorical_accuracy: 0.8547 - val_loss: 2.5413 - val_accuracy: 0.3529 - val_top_k_categorical_accuracy: 0.6597\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}